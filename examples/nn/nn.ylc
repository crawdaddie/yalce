import ../../lib/Math;
import ../../lib/Arrays;
import dataset;

let print_arr = fn arr: (Array of Double) ->
  match (array_size arr) with
  | 0 -> ()
  | _ -> (
    print `arr: {arr @ 0}\n`;
    print_arr (array_succ arr);
    ()
  )
;;

let (@) = array_at;

type Matrix = (
  rows: Int,
  cols: Int,
  data: Array of Double
);

let print_matrix = fn m: (Matrix) ->
  for i = 0 to (m.rows - 1) in (
    for j = 0 to (m.cols - 1) in (
      print `{m.data @ (i * m.cols + j)}, `
    );
    print "\n"
  )
;;

type Layer = (
  weights: Matrix,
  biases: Array of Double,
  activation: ((Array of Double) -> (Array of Double))
);

let matrix_zeroes = fn c r ->
  Matrix r c (array_fill_const (r * c) 0.)
;;

let matrix_to_str = fn m: (Matrix) ->
  ""
;;


let relu = fn x: (Array of Double) -> 
  let loop = fn x: (Array of Double) ->
    match (array_size x) with
    | 0 -> x
    | _ -> (
      let v = x @ 0;
      let relu_v = match v with
      | v if v > 0. -> v
      | _ -> 0.
      ;
      array_set 0 x relu_v;
      loop (array_succ x)
    )
  ;;
  loop x;
  x 

;;
let identity = fn x: (Array of Double) -> x;;

let mse_loss = fn predictions: (Array of Double) targets: (Array of Double) ->
  let loop = fn sum: (Double) p: (Array of Double) t: (Array of Double) ->
    match (array_size p) with
    | 0 -> sum
    | _ -> (

      let pv = p @ 0;
      let tv = t @ 0;
      let loss = Math.pow (pv - tv) 2.;
      loop (sum + loss) (array_succ p) (array_succ t)
    )
  ;;
  let sum = loop 0. predictions targets;
  sum / (array_size predictions)
;;


let matrix_random = fn c r ->
  Matrix r c (array_fill (r * c) (fn i: (Int) -> Math.rand_double_range -1. 1.))
;;



let max_in = array_fill_const 16 0.; # allocate an input array which is as large as the maximum layer width

type Network = (
  layers: Array of Layer,
  loss: ((Array of Double) -> (Array of Double) -> Double)
);

let MLP = Network [|
  Layer (matrix_random 2 16) (array_fill_const 16 0.01) relu,
  Layer (matrix_random 16 16) (array_fill_const 16 0.01) relu,
  Layer (matrix_random 16 1) (array_fill_const 1 1.01) identity,
  |] mse_loss
;

let LayerCache = module

  type LCache = (
    pre_activations: (Array of Array of Double),
    activations: (Array of Array of Double)
  );

  let from_network = fn network: (Network) ->
    let num_layers = array_size network.layers;
    let pre_act_sizes = array_fill_const num_layers 0;
    let act_sizes = array_fill_const (num_layers + 1) 0;

    let layer = network.layers @ 0;
    let weights = layer.weights;
    let cols = weights.cols;
    array_set 0 act_sizes cols;
    let first_act_size = cols;


    let pre_acts = array_fill_const num_layers [| 0. |];
    let acts = array_fill_const (num_layers + 1) [| 0. |];

    array_set 0 acts (array_fill_const cols 0.);

    let ir = [| 0 |];
    for layer = iter network.layers in (
      let i = ir @ 0;
      let pre_size = array_size (layer.biases);
      let act_size = array_size (layer.biases);
      array_set (i + 1) acts (array_fill_const act_size 0.); 
      array_set i pre_acts (array_fill_const pre_size 0.); 

      array_set 0 ir (i + 1)
    );
    LCache pre_acts acts
  ;;

;


let forward_cache = LayerCache.from_network MLP;



let _matrix_vec_mul = extern fn Int -> Int -> Ptr of Double -> Ptr of Double -> ();
let matrix_vec_mul = fn m: (Matrix) v: (Array of Double) ->
  _matrix_vec_mul m.rows m.cols (cstr m.data) (cstr v);
  v
;;

let _vec_add = extern fn Int -> Ptr of Double -> Ptr of Double -> ();
let vec_add = fn a: (Array of Double) b: (Array of Double) -> 
  _vec_add (array_size a) (cstr a) (cstr b);
  b
;;




# let write_to = fn from: (Array of Double) to_: (Array of Double) ->
#   Arrays.fold (fn t v ->
#     array_set 0 t v;
#     array_succ t
#   ) to_ from
# ;;

let write_to = fn to_: (Array of Double) from: (Array of Double) ->
  Arrays.fold (fn t v ->
    array_set 0 t v;
    array_succ t
  ) to_ from;
  from
;;

let (@+) = vec_add;
let (@*) = matrix_vec_mul;

let forward = fn network: (Network) cache: (LayerCache.LCache) input ->
  let layers = network.layers;

  input |> write_to (cache.pre_activations @ 0);

  # TODO: I have to specify the structural types for now - should be possible to fix one day
  Arrays.foldi (fn i (current, cache): (Array of Double, LayerCache.LCache) layer: (Layer) ->
    let z = current
      |> (@*) layer.weights
      |> (@+) layer.biases
      |> write_to (cache.pre_activations @ i)
      |> layer.activation
      |> write_to (cache.activations @ (i + 1))
      ;

    (z, cache)

  ) (input, cache) layers
;;

let (out, cache) = max_in |> forward MLP forward_cache;
print `{out @ 0}\n`;

print `forward_cache {forward_cache.pre_activations @ 0 @ 4}\n`;

# print_matrix (matrix_random 16 16);

# print `{(array_range 1 dforward_cache_storage) @ 0}\n`;
